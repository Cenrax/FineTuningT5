# Fine Tuning flan-t5-small

Model for a Q&A task that takes a context as additional input along with the question.



Extended work using Peft/LORA
<img width="514" alt="image" src="https://github.com/Cenrax/FineTuningT5/assets/43017632/9c228ad2-1d26-482d-a0a6-64da0b64ca6c">

Further works:

- Efficient Finetuning using LORA on a proper GPU

Note: The result of the output is not great because colab was running out of ram for this.
